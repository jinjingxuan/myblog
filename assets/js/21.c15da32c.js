(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{326:function(t,s,a){t.exports=a.p+"assets/img/trie.37bb7564.png"},327:function(t,s,a){t.exports=a.p+"assets/img/patricia.df4b247c.png"},328:function(t,s,a){t.exports=a.p+"assets/img/decentralization.5cee76de.png"},329:function(t,s,a){t.exports=a.p+"assets/img/decentralization1.df2e6b7e.png"},330:function(t,s,a){t.exports=a.p+"assets/img/eth-ex.51657193.jpg"},331:function(t,s,a){t.exports=a.p+"assets/img/eth-ex2.ca85dd23.jpg"},332:function(t,s,a){t.exports=a.p+"assets/img/eth-ex3.cf339024.jpg"},333:function(t,s,a){t.exports=a.p+"assets/img/eth-ex4.29e25859.png"},561:function(t,s,a){"use strict";a.r(s);var e=a(14),n=Object(e.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"北大肖臻老师《区块链技术与应用》公开课学习-5"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#北大肖臻老师《区块链技术与应用》公开课学习-5"}},[t._v("#")]),t._v(" 北大肖臻老师《区块链技术与应用》公开课学习 5")]),t._v(" "),s("ul",[s("li",[t._v("学习地址："),s("a",{attrs:{href:"https://www.bilibili.com/video/BV1Vt411X7JF",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.bilibili.com/video/BV1Vt411X7JF"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("参考文章："),s("a",{attrs:{href:"https://blog.nowcoder.net/n/f6a89f59329542eb9216caa8ca2c843d",target:"_blank",rel:"noopener noreferrer"}},[t._v("北京大学肖臻老师《区块链技术与应用》公开课笔记15——ETH概述篇"),s("OutboundLink")],1)])]),t._v(" "),s("h2",{attrs:{id:"eth-概述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eth-概述"}},[t._v("#")]),t._v(" ETH 概述")]),t._v(" "),s("p",[s("code",[t._v("BTC")]),t._v(" 和 "),s("code",[t._v("ETH")]),t._v(" 为最主要的两种加密货币，"),s("code",[t._v("BTC")]),t._v(" 称为区块链 "),s("code",[t._v("1.0")]),t._v("，以太坊称为区块链 "),s("code",[t._v("2.0")]),t._v("。因为了比特币设计中存在某些不足，以太坊便对其进行了改进。例如：")]),t._v(" "),s("ul",[s("li",[t._v("出块时间: 以太坊出块时间降低到十几秒，以及设计了一套共识协议")]),t._v(" "),s("li",[s("code",[t._v("mining puzzle")]),t._v(": "),s("code",[t._v("BTC")]),t._v(" 挖矿属于计算密集型，挖矿设备专业化（ASIC），以太坊设计的 "),s("code",[t._v("mining puzzle")]),t._v(" 对内存要求高，限制了 "),s("code",[t._v("ASIC")]),t._v(" 的使用（ASIC resistance）")]),t._v(" "),s("li",[t._v("未来，以太坊还将会用权益证明(proof of stake)替代工作量证明(proof of work)")]),t._v(" "),s("li",[t._v("此外，以太坊增加了对智能合约（smart contract）的支持。")])]),t._v(" "),s("h3",{attrs:{id:"为什么智能合约"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么智能合约"}},[t._v("#")]),t._v(" 为什么智能合约")]),t._v(" "),s("p",[s("code",[t._v("BTC")]),t._v(" 本身是一个去中心化的货币，在比特币取得成功之后，很多人就开始思考：除了货币可以去中心化，还有什么可以去中心化？以太坊的一个特性就是增加了对去中心化的合约的支持。")]),t._v(" "),s("ul",[s("li",[t._v("BitCoin: decenralized currency, BTC, 最小单位一聪")]),t._v(" "),s("li",[t._v("Ethereum: decenralized contract, ETH, 最小单位一"),s("code",[t._v("wei")])])]),t._v(" "),s("p",[t._v("货币本身由政府发行，政府公信力为其背书，"),s("code",[t._v("BTC")]),t._v(" 通过技术手段取代了政府的职能。\n现实生活中，我们经常提到 "),s("code",[t._v("契约")]),t._v(" 或 "),s("code",[t._v("合约")]),t._v("。合约的有效性也是需要政府进行维护的，如果产生纠纷需要针对合法性合同进行判决（打官司）。"),s("code",[t._v("ETH")]),t._v(" 的设计目的就是，通过技术手段来实现取代政府对于合约的职能（区块链的不可篡改性）。并不是所有的合同都可以实现，比较简单的可以使用智能合约。")]),t._v(" "),s("p",[t._v("智能合约有什么好处？")]),t._v(" "),s("blockquote",[s("p",[t._v("去中心化的货币的好处是跨国转账，比法币快很多。\n智能合约: 若合同签署方并非一个国家，没有统一的司法部门。如果可以编写无法修改的合约，所有人只能按照相关参与方执行，无法违约。")])]),t._v(" "),s("h2",{attrs:{id:"eth-账户"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eth-账户"}},[t._v("#")]),t._v(" ETH 账户")]),t._v(" "),s("p",[s("code",[t._v("BTC")]),t._v(" 系统是基于交易的账本，系统中并未显示记录账户有多少钱，只能通过 "),s("code",[t._v("UTXO")]),t._v(" 进行推算。这种隐私保护比较好，但是使用起来比较别扭。比如 "),s("code",[t._v("A")]),t._v(" 转给 "),s("code",[t._v("B")]),t._v(" 比特币的时候，"),s("code",[t._v("A")]),t._v(" 需要说明币的来源。但是我们实际中存钱说明来源，花钱则不用。此外，"),s("code",[t._v("BTC")]),t._v(" 账户中的钱在花的时候，必须一次性全部花出去。")]),t._v(" "),s("blockquote",[s("p",[t._v("A => B(10BTC)   B => C(3BTC)\n如果 B 只转给 C 3个 BTC，那么剩下的 7个 BTC 将作为交易费给矿工，所以还要将剩下的钱转给自己：B => B'(7 BTC)\n比特币系统中没有显式的基于账户的模型\n而以太坊系统则采用了基于账户的模型，与现实中银行账户相似。")])]),t._v(" "),s("p",[t._v("优点：转账是否合法只需要查看转账者账户中以太币是否足够即可，同时也不需要每次全部转账，这也天然地防范了双花攻击。（你要是花两次我就从你账户扣两次钱）\n缺点：重放攻击："),s("code",[t._v("A")]),t._v(" 向 "),s("code",[t._v("B")]),t._v(" 转账，过一段时间，"),s("code",[t._v("B")]),t._v(" 将 "),s("code",[t._v("A")]),t._v(" 的交易重新发布，从而导致 "),s("code",[t._v("A")]),t._v("账户被扣钱两次。")]),t._v(" "),s("blockquote",[s("p",[t._v("为了防范重放攻击，给账户交易添加计数器记录该账户交易过多少次，转账时候将转账次数计入交易的内容中。\n系统中全节点维护账户余额和该计数器的交易数，从而防止本地篡改余额或进行重放攻击。\n交易内容：A => B(10ETH)、nonce = 21(这是第21次交易)、Signed by A\n如果重放上述交易内容，会发现 nonce = 21 的交易已经被发布了，就不会执行了。")])]),t._v(" "),s("p",[t._v("以太坊系统中存在两类账户：外部账户和合约账户。")]),t._v(" "),s("ul",[s("li",[t._v("外部账户：类似于 "),s("code",[t._v("BTC")]),t._v(" 系统中公私钥对。存在账户余额 "),s("code",[t._v("balance")]),t._v(" 和计数器 "),s("code",[t._v("nonce")])]),t._v(" "),s("li",[t._v("合约账户：并非通过公私钥对控制。合约账户不能主动发起交易，只能接收到外部账户调用后才能发起交易或调用其他合约账户。其除了"),s("code",[t._v("balance")]),t._v(" 和 "),s("code",[t._v("nonce")]),t._v(" 之外还有 "),s("code",[t._v("code")]),t._v(" (代码)、"),s("code",[t._v("storage")]),t._v(" (相关状态-存储)")])]),t._v(" "),s("p",[t._v("创建合约时候会返回一个地址，就可以对其调用。调用过程中，代码不变但状态会发生改变。")]),t._v(" "),s("h3",{attrs:{id:"为什么以太坊要基于账户的模型"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#为什么以太坊要基于账户的模型"}},[t._v("#")]),t._v(" 为什么以太坊要基于账户的模型")]),t._v(" "),s("p",[t._v("比特币隐私保护比较好，支持每次交易都更换账户。但以太坊是为了支持智能合约，而合约签订双方是比较稳定的身份且较少变化的。尤其是对于合约账户来说，需要保持稳定状态。")]),t._v(" "),s("h2",{attrs:{id:"eth-状态树"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eth-状态树"}},[t._v("#")]),t._v(" ETH 状态树")]),t._v(" "),s("p",[t._v("首先，我们要实现从账户地址到账户状态的映射。在以太坊中，账户地址为 "),s("code",[t._v("160字节")]),t._v(" ，表示为 "),s("code",[t._v("40个16进制")]),t._v("。状态包含了余额(balance)、交易次数(nonce)，合约账户中还包含了代码(code)、存储(stroge)。")]),t._v(" "),s("p",[t._v("直观地来看，其本质上为 "),s("code",[t._v("key-value")]),t._v(" 键值对，所以直观想法便用哈希表实现。若不考虑哈希碰撞，查询直接为常数级别的查询效率。但采用哈希表，难以提供 "),s("code",[t._v("Merkle proof")])]),t._v(" "),s("ol",[s("li",[t._v("我们能否像 "),s("code",[t._v("BTC")]),t._v("，将哈希表的内容组织为 "),s("code",[t._v("Merkle Tree")]),t._v(" ？")])]),t._v(" "),s("blockquote",[s("p",[t._v("当新区块发布，哈希表内容会改变，再次将其组织为新的 "),s("code",[t._v("Merkle Tree")]),t._v("。如果这样，每当产生新区块("),s("code",[t._v("ETH")]),t._v(" 中新区块产生时间为"),s("code",[t._v("10s")]),t._v("左右)，都要重新组织 "),s("code",[t._v("Merkle Tree")]),t._v("，很明显这是不现实的。\n需要注意的是，比特币系统中没有账户概念，交易由区块管理，而区块包含上限为 "),s("code",[t._v("4000")]),t._v(" 个交易左右，所以 "),s("code",[t._v("Merkle Tree")]),t._v(" 不是无限增大的。而 "),s("code",[t._v("ETH")]),t._v(" 中，"),s("code",[t._v("Merkle Tree")]),t._v(" 来组织账户信息，很明显其会越来越庞大。\n实际中，发生变化的仅仅为很少一部分数据，我们每次重新构建 Merkle Tree 代价很大")])]),t._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[t._v("那我们不要哈希表了，直接使用 "),s("code",[t._v("Merkle Tree")]),t._v(" 把所有的账户都放进去，每次修改只需要修改其中一部分即可，这个可以吗？")])]),t._v(" "),s("blockquote",[s("p",[t._v("实际中，"),s("code",[t._v("Merkle Tree")]),t._v(" 并未提供一个高效的查找和更新的方案。此外，将所有账户构建为一个大的 "),s("code",[t._v("Merkle Tree")]),t._v("，为了保证所有节点的一致性和查找速度，必须进行排序。")])]),t._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[t._v("不排序有什么问题?")])]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("Merkle Tree")]),t._v(" 的叶子节点是账户信息，如果不排序，系统中有很多全节点会按照自己的排序方式进行构造账户信息，导致 "),s("code",[t._v("Merkle Tree")]),t._v(" 均不相同，根哈希值也不同。")])]),t._v(" "),s("ol",{attrs:{start:"4"}},[s("li",[t._v("比特币的 "),s("code",[t._v("Merkle Tree")]),t._v(" 不也没排序吗？")])]),t._v(" "),s("blockquote",[s("p",[t._v("比特币每个全节点收到的交易顺序也是不一致的，"),s("code",[t._v("Merkle Tree")]),t._v(" 根哈希值也不一样。但是比特币是每个节点在本地组装一个候选区块，它自己决定收集哪些交易，然后去挖矿争夺记账权，只有挖到矿的人才能决定发布区块，这个顺序是唯一的。")])]),t._v(" "),s("ol",{attrs:{start:"5"}},[s("li",[t._v("那么经过排序，使用 "),s("code",[t._v("Sorted Merkle Tree")]),t._v(" 可以吗？")])]),t._v(" "),s("blockquote",[s("p",[t._v("新增账户，由于其地址随机，插入 "),s("code",[t._v("Merkle Tree")]),t._v(" 时候很大可能在 "),s("code",[t._v("Tree")]),t._v(" 中间，必须进行重构。所以 "),s("code",[t._v("Sorted Merkle Tree")]),t._v(" 插入、删除的代价太大。")])]),t._v(" "),s("h3",{attrs:{id:"mpt"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mpt"}},[t._v("#")]),t._v(" MPT")]),t._v(" "),s("p",[t._v("以太坊采取的数据结构："),s("code",[t._v("MPT")]),t._v("，首先介绍一下 "),s("code",[t._v("trie")]),t._v(" 前缀树（字典树）\n"),s("img",{attrs:{src:a(326),alt:""}})]),t._v(" "),s("ol",[s("li",[s("code",[t._v("trie")]),t._v(" 中每个节点的分支数目取决于每个元素的取值范围(图例中最多"),s("code",[t._v("26")]),t._v("个英文字母分叉+ "),s("code",[t._v("1")]),t._v("个结束标志位)。以太坊中是16进制表示（0 ~ f）加上一个结束标识符为 "),s("code",[t._v("17")]),t._v(" 个分叉。")]),t._v(" "),s("li",[s("code",[t._v("trie")]),t._v(" 查找效率取决于 "),s("code",[t._v("key")]),t._v(" 的长度。实际应用中（以太坊地址长度为160字节）。")]),t._v(" "),s("li",[s("code",[t._v("trie")]),t._v(" 上面不会发生哈希碰撞，两个账户的地址不一样，映射到 "),s("code",[t._v("trie")]),t._v(" 一定是不同的分支。")]),t._v(" "),s("li",[t._v("给定输入，无论如何顺序插入，构造的 "),s("code",[t._v("trie")]),t._v(" 都是一样的。")]),t._v(" "),s("li",[t._v("更新的局部性比较好：每次发布一个区块，系统中绝大多数账户的状态是不变的，只有个别才会变，所以更新操作的局部性很重要。"),s("code",[t._v("trie")]),t._v(" 上只需要遍历某一个分支，并不需要遍历整棵树。")]),t._v(" "),s("li",[t._v("缺点：存储上会有浪费，很多节点只有一个子节点。因此引入了 "),s("code",[t._v("Patricia tree/trie")]),t._v("（经过路径压缩后的前缀树）。")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(327),alt:""}})]),t._v(" "),s("p",[t._v("需要注意的是，如果新插入单词，原本压缩的路径可能需要扩展开来。什么情况下路径压缩效果较好？树中插入的键值分布较为稀疏的情况下，路径压缩效果较好。看以下例子：")]),t._v(" "),s("p",[s("img",{attrs:{src:a(328),alt:""}})]),t._v(" "),s("p",[s("img",{attrs:{src:a(329),alt:""}})]),t._v(" "),s("p",[t._v("在以太坊系统中，"),s("code",[t._v("160")]),t._v(" 位的地址存在 "),s("code",[t._v("2^160")]),t._v(" 种，以太坊全世界的账户数加一起也远不足这个数，为什么地址搞的这么稀疏呢？")]),t._v(" "),s("blockquote",[s("p",[t._v("就是因为地址分布稀疏，所以路径压缩效果较好。\n以太坊创建账户在本地创建即可，类似于比特币，那么会不会两个创建的账户地址一样呢？有可能，但是比地球爆炸的可能性还要低，就是因为地址足够长，足够稀疏。\n实际上，在以太坊种使用的并非简单的 "),s("code",[t._v("Patricia tree")]),t._v("，而是 "),s("code",[t._v("MPT(Merkle Patricia tree)")])])]),t._v(" "),s("p",[s("code",[t._v("MPT")]),t._v(" 就是将所有账户组织为一个经过路径压缩和排序的 "),s("code",[t._v("Merkle Tree")]),t._v(" (指针为哈希指针)，其根哈希值存储于 "),s("code",[t._v("block header")]),t._v(" 中。根哈希值的用处：")]),t._v(" "),s("ol",[s("li",[t._v("防止篡改。")]),t._v(" "),s("li",[t._v("提供 "),s("code",[t._v("Merkle proof")]),t._v(" ，可以证明账户余额，轻节点可以进行验证。")]),t._v(" "),s("li",[t._v("给一个账户转账之前，证明某个发生了交易的账户是否存在。")])]),t._v(" "),s("p",[t._v("以太坊中针对 "),s("code",[t._v("MPT")]),t._v(" 进行了修改，我们称其为 "),s("code",[t._v("Modified MPT")]),t._v("。")]),t._v(" "),s("p",[s("img",{attrs:{src:a(330),alt:""}})]),t._v(" "),s("ul",[s("li",[t._v("shared nibble(s)：十六进制")]),t._v(" "),s("li",[t._v("extension node：扩展节点，经过路径压缩的节点")]),t._v(" "),s("li",[t._v("leaf node：叶子节点")]),t._v(" "),s("li",[t._v("branch node：分支节点")])]),t._v(" "),s("p",[t._v("每次发布新区块，状态树中部分节点状态会改变。但改变并非在原地修改，而是新建一些分支，保留原本状态。如下图中，仅仅有新发生改变的节点才需要修改，其他未修改节点直接指向前一个区块中的对应节点。")]),t._v(" "),s("p",[s("img",{attrs:{src:a(331),alt:""}})]),t._v(" "),s("p",[t._v("所以，系统中全节点并非维护一棵MPT，而是每次发布新区块都要新建MPT。只不过大部分节点共享。")]),t._v(" "),s("blockquote",[s("p",[t._v("为什么要保存原本状态？为何不直接修改？\n为了便于回滚。如产生分叉后上面节点胜出，那么下面节点中状态的修改便需要进行回滚。因此，需要维护这些历史记录。")])]),t._v(" "),s("p",[s("strong",[t._v("block header 中的数据结构")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(332),alt:""}})]),t._v(" "),s("ul",[s("li",[t._v("Parenthash: 父区块的哈希（前一个区块的哈希）")]),t._v(" "),s("li",[t._v("Unclehash: 叔父区块的哈希")]),t._v(" "),s("li",[t._v("Coinbase: 矿工地址")]),t._v(" "),s("li",[t._v("Root: 状态树的根哈希值")]),t._v(" "),s("li",[t._v("Txhash: 交易树的根哈希值")]),t._v(" "),s("li",[t._v("Receipthash: 收据树的根哈希值")]),t._v(" "),s("li",[t._v("Bloom: 整个区块块头的 Bloom filter")]),t._v(" "),s("li",[t._v("Difficulty: 挖矿难度")]),t._v(" "),s("li",[t._v("GasLimit: 汽油费（类似于比特币中的交易费）相关")]),t._v(" "),s("li",[t._v("GasUsed: 汽油费（类似于比特币中的交易费）相关")]),t._v(" "),s("li",[t._v("Time: 区块产生时间")]),t._v(" "),s("li",[t._v("Mixdigest: 挖矿过程随机数算出来的哈希值")]),t._v(" "),s("li",[t._v("Nonce: 挖矿时随机数")])]),t._v(" "),s("p",[s("strong",[t._v("区块结构")])]),t._v(" "),s("p",[s("img",{attrs:{src:a(333),alt:""}})]),t._v(" "),s("ul",[s("li",[t._v("header: 指向 block header 的指针")]),t._v(" "),s("li",[t._v("uncles: 指向叔父区块的指针")]),t._v(" "),s("li",[t._v("transactions: 交易列表")])]),t._v(" "),s("p",[s("strong",[t._v("区块在网上真正发布时的信息")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("type extblock struct {\n    Header *Header\n    Txs    []*Transactions\n    uncles []*Header\n}\n")])])]),s("blockquote",[s("p",[t._v("状态树中保存 "),s("code",[t._v("Key-value")]),t._v(" 对，"),s("code",[t._v("key")]),t._v(" 就是地址，而 "),s("code",[t._v("value")]),t._v(" 状态通过 "),s("code",[t._v("RLP(Recursive Length Prefix，一种进行序列化的方法)")]),t._v(" 编码序列号之后再进行存储。")])]),t._v(" "),s("h2",{attrs:{id:"eth-交易树和收据树"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#eth-交易树和收据树"}},[t._v("#")]),t._v(" ETH 交易树和收据树")]),t._v(" "),s("p",[t._v("每次发布一个区块时，区块中的交易会形成一颗 "),s("code",[t._v("Merkle Tree")]),t._v("，即交易树。此外以太坊还添加了一个收据树，每个交易执行完之后形成一个收据，记录交易相关信息。交易树和收据树上的节点是一一对应的，且都是 "),s("code",[t._v("MPT")]),t._v("。"),s("code",[t._v("MPT")]),t._v(" 的好处是支持查找操作，通过键值沿着树进行查找即可。")]),t._v(" "),s("ul",[s("li",[t._v("对于状态树，查找键值为账户地址。")]),t._v(" "),s("li",[t._v("对于交易树和收据树，查找键值为交易在发布的区块中的序号。")])]),t._v(" "),s("p",[t._v("收据树作用：在以太坊中最重要的功能是加入了智能合约，而智能合约的执行过程比较复杂，收据树的作用是利于系统快速查询执行结果。")]),t._v(" "),s("h3",{attrs:{id:"布隆过滤器-bloom-filter"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#布隆过滤器-bloom-filter"}},[t._v("#")]),t._v(" 布隆过滤器(Bloom filter)")]),t._v(" "),s("p",[t._v("作用：布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。")]),t._v(" "),s("blockquote",[s("p",[t._v("给定一个数据集，其中含义元素 "),s("code",[t._v("a、b、c")]),t._v("，通过一个哈希函数 "),s("code",[t._v("H()")]),t._v(" 对其进行计算，将其映射到一个其初始全为 "),s("code",[t._v("0")]),t._v(" 的 "),s("code",[t._v("128")]),t._v(" 位的向量的某个位置，将该位置置为 "),s("code",[t._v("1")]),t._v("。将所有元素处理完，就可以得到一个向量，则称该向量为原集合的 "),s("code",[t._v("摘要")]),t._v("。该 "),s("code",[t._v("摘要")]),t._v(" 比原集合是要小很多的。\n假定想要查询一个元素 "),s("code",[t._v("d")]),t._v(" 是否在集合中，假设 "),s("code",[t._v("H(d)")]),t._v(" 映射到向量中的位置处为 "),s("code",[t._v("0")]),t._v("，说明 "),s("code",[t._v("d")]),t._v("一定不在集合中；假设 "),s("code",[t._v("H(d)")]),t._v("映射到向量中的位置处为 "),s("code",[t._v("1")]),t._v("，可能集合中确实有 "),s("code",[t._v("d")]),t._v("，也有可能因为哈希碰撞产生误报。\n个人理解就是：他会告诉你某样东西一定不存在或者可能存在。")])]),t._v(" "),s("h4",{attrs:{id:"bloom-filter-在以太坊中的应用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bloom-filter-在以太坊中的应用"}},[t._v("#")]),t._v(" Bloom filter 在以太坊中的应用")]),t._v(" "),s("p",[t._v("每个交易完成后会产生一个收据，收据包含一个 "),s("code",[t._v("Bloom filter")]),t._v(" 记录交易类型、地址等信息。在区块 "),s("code",[t._v("block header")]),t._v(" 中也包含一个"),s("code",[t._v("Bloom filter")]),t._v("，其为该区块中所有交易的 "),s("code",[t._v("Bloom filter")]),t._v(" 的一个并集。\n所以，查找时候先查找块头中的 "),s("code",[t._v("Bloom filter")]),t._v("，如果块头中包含。再查看区块中包含的交易的 "),s("code",[t._v("Bloom filter")]),t._v("，如果存在，再查看交易进行确认；如果不存在，则说明发生了 "),s("code",[t._v("碰撞")]),t._v("。\n好处就是通过 "),s("code",[t._v("Bloom filter")]),t._v(" 这样一个结构，快速大量过滤掉大量无关区块，从而提高了查找效率。")]),t._v(" "),s("h3",{attrs:{id:"补充"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#补充"}},[t._v("#")]),t._v(" 补充")]),t._v(" "),s("p",[t._v("以太坊对于给定的当前状态和给定一组交易可以确定性的转移到下一状态，这一运行过程可以视为"),s("strong",[t._v("交易驱动的状态机")]),t._v("，通过执行当前区块中包含的交易，驱动系统从当前状态转移到下一状态。当然，"),s("code",[t._v("BTC")]),t._v(" 我们也可以视为交易驱动的状态机，其状态为 "),s("code",[t._v("UTXO")]),t._v("。")]),t._v(" "),s("p",[t._v("问题1：A转账到B，有没有可能收款账户不包含再状态树中？")]),t._v(" "),s("blockquote",[s("p",[t._v("可能。因为以太坊中账户可以节点自己产生，只有在产生交易时才会被系统知道。\n问题2：可否将每个区块中状态树更改为只包含和区块中交易相关的账户状态？(大幅削减状态树大小，且和交易树、收据树保持一致)\n不能。首先，这样设计要查找账户状态很不方便，因为不存在某个区块包含所有状态。其次，如果要向一个新创建账户转账，因为需要知道收款账户的状态，才能给其添加金额，但由于其是新创建的账户，所有需要一直找到创世纪块才能知道该账户为新建账户。")])]),t._v(" "),s("h3",{attrs:{id:"代码实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#代码实现"}},[t._v("#")]),t._v(" 代码实现")]),t._v(" "),s("div",{staticClass:"language-go extra-class"},[s("pre",{pre:!0,attrs:{class:"language-go"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("NewBlock")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("header "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" txs "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Transaction"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uncles "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" receipts "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Receipt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hasher TrieHasher"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Block "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("Block"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("CopyHeader")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\t"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 交易列表是否为空")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("txs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 块头里的交易树的根哈希值为空哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TxHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EmptyTxsHash\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 调用 DeriveSha 获得根哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TxHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("DeriveSha")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Transactions")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("txs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hasher"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建交易列表")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transactions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("make")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Transactions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("txs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t\t"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("copy")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transactions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" txs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 收据列表是否为空")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("receipts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 块头里的收据树的根哈希值为空哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReceiptHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EmptyReceiptsHash\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 调用 DeriveSha 获得根哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ReceiptHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("DeriveSha")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Receipts")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("receipts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" hasher"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建 Bloom Filter")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// CreateBloom 函数用来创建 Block Header 中的 Bloom 域,")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个 Bloom Filter 由这个块中所有 receiptes 的 Bloom Filter 组合得到")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Bloom "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("CreateBloom")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("receipts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 叔父列表是否为空")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncles"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 块头里的叔父区块的哈希值为空哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UncleHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EmptyUncleHash\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 通过 CalcUncleHash 计算出哈希值")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("UncleHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("CalcUncleHash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncles"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 通过循环构造出叔父数组")]),t._v("\n\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uncles "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("make")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Header"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncles"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("range")]),t._v(" uncles "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\t\tb"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("uncles"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("CopyHeader")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("uncles"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" b\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// DeriveSha 函数")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("func")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("DeriveSha")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list DerivableList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" common"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Hash "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tkeybuf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("new")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bytes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Buffer"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ttrie "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("new")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("trie"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Trie"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\t\tkeybuf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Reset")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t\trlp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Encode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("keybuf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("uint")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t\ttrie"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Update")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("keybuf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Bytes")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" list"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("GetRlp")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" trie"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("Hash")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 收据数据结构")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("type")]),t._v(" Receipt "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n\tPostState         "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("byte")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"root"`')]),t._v("\n\tStatus            "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint64")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"status"`')]),t._v("\n\tCumulativeGasUsed "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint64")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"cumulativeGasUsed" gencodec:"required"`')]),t._v("\n\tBloom             Bloom  "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"logsBloom"         gencodec:"required"`')]),t._v("\n\tLogs              "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("Log "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"logs"              gencodec:"required"`')]),t._v("\n\n\tTxHash          common"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Hash    "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"transactionHash" gencodec:"required"`')]),t._v("\n\tContractAddress common"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Address "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"contractAddress"`')]),t._v("\n\tGasUsed         "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("uint64")]),t._v("         "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('`json:"gasUsed" gencodec:"required"`')]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);